{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recruit Restaurant Visitor Forecasting\n",
    "\n",
    "## Prerequisites\n",
    "Please make sure the following Python distributions and packages were installed.\n",
    "\n",
    "* [Anaconda](https://anaconda.org)\n",
    "* [XGBoost](https://github.com/dmlc/xgboost)\n",
    "* [LightGBM](https://github.com/Microsoft/LightGBM) - not needed by week 1\n",
    "* [Keras](https://keras.io) - not needed by week 1\n",
    "* [Tensorflow](https://www.tensorflow.org) - not needed by week 1\n",
    "* [Bayesian Optimization](https://github.com/fmfn/BayesianOptimization) - not needed by week 1\n",
    "* [seaborn](https://seaborn.pydata.org)\n",
    "* [bokeh](http://bokeh.pydata.org)\n",
    "\n",
    "You'll also need to create the following sub-folders in your working folder:\n",
    "\n",
    "* input\n",
    "   \n",
    "   To store all the data files downloaded from Kaggle\n",
    "   \n",
    "   \n",
    "* output\n",
    "    \n",
    "    To store submission files\n",
    "   \n",
    "   \n",
    "* python\n",
    "    \n",
    "    To store python scripts and ipython notebooks including this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jyguo/miniconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "# import lightgbm as lgb - will be used in following weeks\n",
    "# from bayes_opt import BayesianOptimization - will be used in following weeks\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from sklearn import preprocessing, pipeline, metrics, model_selection\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression,RidgeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from IPython.display import display\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../input/air_visit_data.csv')\n",
    "air_store_info = pd.read_csv('../input/air_store_info.csv')\n",
    "hpg_store_info = pd.read_csv('../input/hpg_store_info.csv')\n",
    "air_reserve = pd.read_csv('../input/air_reserve.csv')\n",
    "hpg_reserve = pd.read_csv('../input/hpg_reserve.csv')\n",
    "store_id_relation = pd.read_csv('../input/store_id_relation.csv')\n",
    "test_data = pd.read_csv('../input/sample_submission.csv')\n",
    "date_info = pd.read_csv('../input/date_info.csv').rename(columns={'calendar_date':'visit_date'})\n",
    "train_size = train_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic preprocessing\n",
    "#### Take a look at train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  visit_date  visitors\n",
       "0  air_ba937bf13d40fb24  2016-01-13        25\n",
       "1  air_ba937bf13d40fb24  2016-01-14        32\n",
       "2  air_ba937bf13d40fb24  2016-01-15        29\n",
       "3  air_ba937bf13d40fb24  2016-01-16        22\n",
       "4  air_ba937bf13d40fb24  2016-01-18         6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  visitors\n",
       "0  air_00a91d42b08b08d9_2017-04-23         0\n",
       "1  air_00a91d42b08b08d9_2017-04-24         0\n",
       "2  air_00a91d42b08b08d9_2017-04-25         0\n",
       "3  air_00a91d42b08b08d9_2017-04-26         0\n",
       "4  air_00a91d42b08b08d9_2017-04-27         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_data.head())\n",
    "display(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split air_store_id and visit_date from id for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitors</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>air_store_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-23</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-23</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-24</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-24</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-25</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-25</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-26</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-26</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9_2017-04-27</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-27</td>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  visitors  visit_date          air_store_id\n",
       "0  air_00a91d42b08b08d9_2017-04-23         0  2017-04-23  air_00a91d42b08b08d9\n",
       "1  air_00a91d42b08b08d9_2017-04-24         0  2017-04-24  air_00a91d42b08b08d9\n",
       "2  air_00a91d42b08b08d9_2017-04-25         0  2017-04-25  air_00a91d42b08b08d9\n",
       "3  air_00a91d42b08b08d9_2017-04-26         0  2017-04-26  air_00a91d42b08b08d9\n",
       "4  air_00a91d42b08b08d9_2017-04-27         0  2017-04-27  air_00a91d42b08b08d9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['visit_date'] = test_data['id'].map(lambda x: str(x).split('_')[2])\n",
    "test_data['air_store_id'] = test_data['id'].map(lambda x: '_'.join(x.split('_')[:2]))\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge training and testing data\n",
    "This is to simplify the efforts for feature engineering otherwise we'll have to perform the same transfromations for both train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id   id  visit_date  visitors\n",
       "0  air_ba937bf13d40fb24  NaN  2016-01-13        25\n",
       "1  air_ba937bf13d40fb24  NaN  2016-01-14        32\n",
       "2  air_ba937bf13d40fb24  NaN  2016-01-15        29\n",
       "3  air_ba937bf13d40fb24  NaN  2016-01-16        22\n",
       "4  air_ba937bf13d40fb24  NaN  2016-01-18         6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32014</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>air_fff68b929994bfbd_2017-05-27</td>\n",
       "      <td>2017-05-27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32015</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>air_fff68b929994bfbd_2017-05-28</td>\n",
       "      <td>2017-05-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32016</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>air_fff68b929994bfbd_2017-05-29</td>\n",
       "      <td>2017-05-29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32017</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>air_fff68b929994bfbd_2017-05-30</td>\n",
       "      <td>2017-05-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32018</th>\n",
       "      <td>air_fff68b929994bfbd</td>\n",
       "      <td>air_fff68b929994bfbd_2017-05-31</td>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               air_store_id                               id  visit_date  \\\n",
       "32014  air_fff68b929994bfbd  air_fff68b929994bfbd_2017-05-27  2017-05-27   \n",
       "32015  air_fff68b929994bfbd  air_fff68b929994bfbd_2017-05-28  2017-05-28   \n",
       "32016  air_fff68b929994bfbd  air_fff68b929994bfbd_2017-05-29  2017-05-29   \n",
       "32017  air_fff68b929994bfbd  air_fff68b929994bfbd_2017-05-30  2017-05-30   \n",
       "32018  air_fff68b929994bfbd  air_fff68b929994bfbd_2017-05-31  2017-05-31   \n",
       "\n",
       "       visitors  \n",
       "32014         0  \n",
       "32015         0  \n",
       "32016         0  \n",
       "32017         0  \n",
       "32018         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_data = pd.concat([train_data,test_data])\n",
    "display(full_data.head())\n",
    "display(full_data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datetime features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_data['visit_date'] = pd.to_datetime(full_data['visit_date'])\n",
    "full_data['dow'] = full_data['visit_date'].dt.dayofweek\n",
    "full_data['year'] = full_data['visit_date'].dt.year\n",
    "full_data['month'] = full_data['visit_date'].dt.month\n",
    "full_data['doy'] = full_data['visit_date'].dt.dayofyear\n",
    "full_data['dom'] = full_data['visit_date'].dt.days_in_month\n",
    "full_data['woy'] = full_data['visit_date'].dt.weekofyear\n",
    "full_data['is_month_end'] = full_data['visit_date'].dt.is_month_end\n",
    "full_data['visit_date'] = full_data['visit_date'].dt.date\n",
    "full_data['date_int'] = full_data['visit_date'].apply(lambda x: x.strftime('%Y%m%d')).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store information\n",
    "\n",
    "There are two types of store information: air and hpg which are two websites where customers can make reservations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split area names\n",
    "\n",
    "It appears that the column area_name actually contains 3 levels of geographic area\n",
    "e.g Tōkyō-to Setagaya-ku Taishidō - > \n",
    "\n",
    "Tōkyō-to\n",
    "\n",
    "    Setagaya-ku\n",
    "\n",
    "        Taishidō\n",
    "Let's split it into 3 new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air_store_info['air_area_lv1'] = air_store_info.air_area_name.apply(lambda x:x.split(' ')[0])\n",
    "air_store_info['air_area_lv2'] = air_store_info.air_area_name.apply(lambda x:x.split(' ')[1])\n",
    "air_store_info['air_area_lv3'] = air_store_info.air_area_name.apply(lambda x:x.split(' ')[2])\n",
    "\n",
    "hpg_store_info['hpg_area_lv1'] = hpg_store_info.hpg_area_name.apply(lambda x:x.split(' ')[0])\n",
    "hpg_store_info['hpg_area_lv2'] = hpg_store_info.hpg_area_name.apply(lambda x:x.split(' ')[1])\n",
    "hpg_store_info['hpg_area_lv3'] = hpg_store_info.hpg_area_name.apply(lambda x:x.split(' ')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>air_area_lv1</th>\n",
       "      <th>air_area_lv2</th>\n",
       "      <th>air_area_lv3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_0f0cdeee6c9bf3d7</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "      <td>Hyōgo-ken</td>\n",
       "      <td>Kōbe-shi</td>\n",
       "      <td>Kumoidōri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_7cc17a324ae5c7dc</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "      <td>Hyōgo-ken</td>\n",
       "      <td>Kōbe-shi</td>\n",
       "      <td>Kumoidōri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_fee8dcf4d619598e</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "      <td>Hyōgo-ken</td>\n",
       "      <td>Kōbe-shi</td>\n",
       "      <td>Kumoidōri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_a17f0778617c76e2</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "      <td>Hyōgo-ken</td>\n",
       "      <td>Kōbe-shi</td>\n",
       "      <td>Kumoidōri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_83db5aff8f50478e</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>Tōkyō-to</td>\n",
       "      <td>Minato-ku</td>\n",
       "      <td>Shibakōen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  air_genre_name                 air_area_name  \\\n",
       "0  air_0f0cdeee6c9bf3d7  Italian/French  Hyōgo-ken Kōbe-shi Kumoidōri   \n",
       "1  air_7cc17a324ae5c7dc  Italian/French  Hyōgo-ken Kōbe-shi Kumoidōri   \n",
       "2  air_fee8dcf4d619598e  Italian/French  Hyōgo-ken Kōbe-shi Kumoidōri   \n",
       "3  air_a17f0778617c76e2  Italian/French  Hyōgo-ken Kōbe-shi Kumoidōri   \n",
       "4  air_83db5aff8f50478e  Italian/French  Tōkyō-to Minato-ku Shibakōen   \n",
       "\n",
       "    latitude   longitude air_area_lv1 air_area_lv2 air_area_lv3  \n",
       "0  34.695124  135.197852    Hyōgo-ken     Kōbe-shi    Kumoidōri  \n",
       "1  34.695124  135.197852    Hyōgo-ken     Kōbe-shi    Kumoidōri  \n",
       "2  34.695124  135.197852    Hyōgo-ken     Kōbe-shi    Kumoidōri  \n",
       "3  34.695124  135.197852    Hyōgo-ken     Kōbe-shi    Kumoidōri  \n",
       "4  35.658068  139.751599     Tōkyō-to    Minato-ku    Shibakōen  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_store_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create features that based on different levels of area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air_store_info = pd.merge(air_store_info,\n",
    "                             air_store_info.groupby(['latitude','longitude']).air_store_id.count().\\\n",
    "                                    reset_index().rename(columns={'air_store_id':'air_stores_on_same_addr'}),\n",
    "                             how='left',\n",
    "                             on=['latitude','longitude'])\n",
    "\n",
    "\n",
    "air_store_info = pd.merge(air_store_info,\n",
    "                             air_store_info.groupby('air_area_lv1').air_store_id.count().\\\n",
    "                                    reset_index().rename(columns={'air_store_id':'air_stores_lv1'}),\n",
    "                             how='left',\n",
    "                             on='air_area_lv1')\n",
    "\n",
    "air_store_info = pd.merge(air_store_info,\n",
    "                             air_store_info.groupby(['air_area_lv1','air_area_lv2']).air_store_id.count().\\\n",
    "                                    reset_index().rename(columns={'air_store_id':'air_stores_lv2'}),\n",
    "                             how='left',\n",
    "                             on=['air_area_lv1','air_area_lv2'])\n",
    "\n",
    "\n",
    "air_store_info = pd.merge(air_store_info,\n",
    "                             air_store_info.groupby('air_area_lv1').latitude.mean().\\\n",
    "                                    reset_index().rename(columns={'latitude':'mean_lat_air_lv1'}),\n",
    "                             how='left',\n",
    "                             on='air_area_lv1')\n",
    "\n",
    "air_store_info = pd.merge(air_store_info,\n",
    "                             air_store_info.groupby('air_area_lv1').latitude.max().\\\n",
    "                                    reset_index().rename(columns={'latitude':'max_lat_air_lv1'}),\n",
    "                             how='left',\n",
    "                             on='air_area_lv1')\n",
    "\n",
    "air_store_info = pd.merge(air_store_info,\n",
    "                             air_store_info.groupby('air_area_lv1').latitude.min().\\\n",
    "                                    reset_index().rename(columns={'latitude':'min_lat_air_lv1'}),\n",
    "                             how='left',\n",
    "                             on='air_area_lv1')\n",
    "\n",
    "\n",
    "air_store_info = pd.merge(air_store_info,\n",
    "                             air_store_info.groupby('air_area_lv1').longitude.mean().\\\n",
    "                                    reset_index().rename(columns={'longitude':'mean_lon_air_lv1'}),\n",
    "                             how='left',\n",
    "                             on='air_area_lv1')\n",
    "\n",
    "air_store_info = pd.merge(air_store_info,\n",
    "                             air_store_info.groupby('air_area_lv1').longitude.max().\\\n",
    "                                    reset_index().rename(columns={'longitude':'max_lon_air_lv1'}),\n",
    "                             how='left',\n",
    "                             on='air_area_lv1')\n",
    "\n",
    "air_store_info = pd.merge(air_store_info,\n",
    "                             air_store_info.groupby('air_area_lv1').longitude.min().\\\n",
    "                                    reset_index().rename(columns={'longitude':'min_lon_air_lv1'}),\n",
    "                             how='left',\n",
    "                             on='air_area_lv1')\n",
    "\n",
    "air_store_info = pd.merge(air_store_info,\n",
    "                             air_store_info.groupby(['air_area_lv1','air_area_lv2']).latitude.mean().\\\n",
    "                                    reset_index().rename(columns={'latitude':'mean_lat_air_lv2'}),\n",
    "                             how='left',\n",
    "                             on=['air_area_lv1','air_area_lv2'])\n",
    "\n",
    "air_store_info = pd.merge(air_store_info,\n",
    "                             air_store_info.groupby(['air_area_lv1','air_area_lv2']).latitude.max().\\\n",
    "                                    reset_index().rename(columns={'latitude':'max_lat_air_lv2'}),\n",
    "                             how='left',\n",
    "                             on=['air_area_lv1','air_area_lv2'])\n",
    "\n",
    "air_store_info = pd.merge(air_store_info,\n",
    "                             air_store_info.groupby(['air_area_lv1','air_area_lv2']).latitude.min().\\\n",
    "                                    reset_index().rename(columns={'latitude':'min_lat_air_lv2'}),\n",
    "                             how='left',\n",
    "                             on=['air_area_lv1','air_area_lv2'])\n",
    "\n",
    "\n",
    "air_store_info = pd.merge(air_store_info,\n",
    "                             air_store_info.groupby(['air_area_lv1','air_area_lv2']).longitude.mean().\\\n",
    "                                    reset_index().rename(columns={'longitude':'mean_lon_air_lv2'}),\n",
    "                             how='left',\n",
    "                             on=['air_area_lv1','air_area_lv2'])\n",
    "\n",
    "air_store_info = pd.merge(air_store_info,\n",
    "                             air_store_info.groupby(['air_area_lv1','air_area_lv2']).longitude.max().\\\n",
    "                                    reset_index().rename(columns={'longitude':'max_lon_air_lv2'}),\n",
    "                             how='left',\n",
    "                             on=['air_area_lv1','air_area_lv2'])\n",
    "\n",
    "air_store_info = pd.merge(air_store_info,\n",
    "                             air_store_info.groupby(['air_area_lv1','air_area_lv2']).longitude.min().\\\n",
    "                                    reset_index().rename(columns={'longitude':'min_lon_air_lv2'}),\n",
    "                             how='left',\n",
    "                             on=['air_area_lv1','air_area_lv2'])\n",
    "\n",
    "\n",
    "hpg_store_info = pd.merge(hpg_store_info,\n",
    "                             hpg_store_info.groupby(['latitude','longitude']).hpg_store_id.count().\\\n",
    "                                    reset_index().rename(columns={'hpg_store_id':'hpg_stores_on_same_addr'}),\n",
    "                             how='left',\n",
    "                             on=['latitude','longitude'])\n",
    "\n",
    "\n",
    "hpg_store_info = pd.merge(hpg_store_info,\n",
    "                             hpg_store_info.groupby('hpg_area_lv1').hpg_store_id.count().\\\n",
    "                                    reset_index().rename(columns={'hpg_store_id':'hpg_stores_lv1'}),\n",
    "                             how='left',\n",
    "                             on='hpg_area_lv1')\n",
    "\n",
    "hpg_store_info = pd.merge(hpg_store_info,\n",
    "                             hpg_store_info.groupby(['hpg_area_lv1','hpg_area_lv2']).hpg_store_id.count().\\\n",
    "                                    reset_index().rename(columns={'hpg_store_id':'hpg_stores_lv2'}),\n",
    "                             how='left',\n",
    "                             on=['hpg_area_lv1','hpg_area_lv2'])\n",
    "\n",
    "\n",
    "hpg_store_info = pd.merge(hpg_store_info,\n",
    "                             hpg_store_info.groupby('hpg_area_lv1').latitude.mean().\\\n",
    "                                    reset_index().rename(columns={'latitude':'mean_lat_hpg_lv1'}),\n",
    "                             how='left',\n",
    "                             on='hpg_area_lv1')\n",
    "\n",
    "hpg_store_info = pd.merge(hpg_store_info,\n",
    "                             hpg_store_info.groupby('hpg_area_lv1').latitude.max().\\\n",
    "                                    reset_index().rename(columns={'latitude':'max_lat_hpg_lv1'}),\n",
    "                             how='left',\n",
    "                             on='hpg_area_lv1')\n",
    "\n",
    "hpg_store_info = pd.merge(hpg_store_info,\n",
    "                             hpg_store_info.groupby('hpg_area_lv1').latitude.min().\\\n",
    "                                    reset_index().rename(columns={'latitude':'min_lat_hpg_lv1'}),\n",
    "                             how='left',\n",
    "                             on='hpg_area_lv1')\n",
    "\n",
    "\n",
    "hpg_store_info = pd.merge(hpg_store_info,\n",
    "                             hpg_store_info.groupby('hpg_area_lv1').longitude.mean().\\\n",
    "                                    reset_index().rename(columns={'longitude':'mean_lon_hpg_lv1'}),\n",
    "                             how='left',\n",
    "                             on='hpg_area_lv1')\n",
    "\n",
    "hpg_store_info = pd.merge(hpg_store_info,\n",
    "                             hpg_store_info.groupby('hpg_area_lv1').longitude.max().\\\n",
    "                                    reset_index().rename(columns={'longitude':'max_lon_hpg_lv1'}),\n",
    "                             how='left',\n",
    "                             on='hpg_area_lv1')\n",
    "\n",
    "hpg_store_info = pd.merge(hpg_store_info,\n",
    "                             hpg_store_info.groupby('hpg_area_lv1').longitude.min().\\\n",
    "                                    reset_index().rename(columns={'longitude':'min_lon_hpg_lv1'}),\n",
    "                             how='left',\n",
    "                             on='hpg_area_lv1')\n",
    "\n",
    "hpg_store_info = pd.merge(hpg_store_info,\n",
    "                             hpg_store_info.groupby(['hpg_area_lv1','hpg_area_lv2']).latitude.mean().\\\n",
    "                                    reset_index().rename(columns={'latitude':'mean_lat_hpg_lv2'}),\n",
    "                             how='left',\n",
    "                             on=['hpg_area_lv1','hpg_area_lv2'])\n",
    "\n",
    "hpg_store_info = pd.merge(hpg_store_info,\n",
    "                             hpg_store_info.groupby(['hpg_area_lv1','hpg_area_lv2']).latitude.max().\\\n",
    "                                    reset_index().rename(columns={'latitude':'max_lat_hpg_lv2'}),\n",
    "                             how='left',\n",
    "                             on=['hpg_area_lv1','hpg_area_lv2'])\n",
    "\n",
    "hpg_store_info = pd.merge(hpg_store_info,\n",
    "                             hpg_store_info.groupby(['hpg_area_lv1','hpg_area_lv2']).latitude.min().\\\n",
    "                                    reset_index().rename(columns={'latitude':'min_lat_hpg_lv2'}),\n",
    "                             how='left',\n",
    "                             on=['hpg_area_lv1','hpg_area_lv2'])\n",
    "\n",
    "\n",
    "hpg_store_info = pd.merge(hpg_store_info,\n",
    "                             hpg_store_info.groupby(['hpg_area_lv1','hpg_area_lv2']).longitude.mean().\\\n",
    "                                    reset_index().rename(columns={'longitude':'mean_lon_hpg_lv2'}),\n",
    "                             how='left',\n",
    "                             on=['hpg_area_lv1','hpg_area_lv2'])\n",
    "\n",
    "hpg_store_info = pd.merge(hpg_store_info,\n",
    "                             hpg_store_info.groupby(['hpg_area_lv1','hpg_area_lv2']).longitude.max().\\\n",
    "                                    reset_index().rename(columns={'longitude':'max_lon_hpg_lv2'}),\n",
    "                             how='left',\n",
    "                             on=['hpg_area_lv1','hpg_area_lv2'])\n",
    "\n",
    "hpg_store_info = pd.merge(hpg_store_info,\n",
    "                             hpg_store_info.groupby(['hpg_area_lv1','hpg_area_lv2']).longitude.min().\\\n",
    "                                    reset_index().rename(columns={'longitude':'min_lon_hpg_lv2'}),\n",
    "                             how='left',\n",
    "                             on=['hpg_area_lv1','hpg_area_lv2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge store information for stores that exist in both air and hpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>air_genre_name</th>\n",
       "      <th>air_area_name</th>\n",
       "      <th>latitude_air</th>\n",
       "      <th>longitude_air</th>\n",
       "      <th>air_area_lv1</th>\n",
       "      <th>air_area_lv2</th>\n",
       "      <th>air_area_lv3</th>\n",
       "      <th>air_stores_on_same_addr</th>\n",
       "      <th>air_stores_lv1</th>\n",
       "      <th>...</th>\n",
       "      <th>min_lat_hpg_lv1</th>\n",
       "      <th>mean_lon_hpg_lv1</th>\n",
       "      <th>max_lon_hpg_lv1</th>\n",
       "      <th>min_lon_hpg_lv1</th>\n",
       "      <th>mean_lat_hpg_lv2</th>\n",
       "      <th>max_lat_hpg_lv2</th>\n",
       "      <th>min_lat_hpg_lv2</th>\n",
       "      <th>mean_lon_hpg_lv2</th>\n",
       "      <th>max_lon_hpg_lv2</th>\n",
       "      <th>min_lon_hpg_lv2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_0f0cdeee6c9bf3d7</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "      <td>Hyōgo-ken</td>\n",
       "      <td>Kōbe-shi</td>\n",
       "      <td>Kumoidōri</td>\n",
       "      <td>17</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_7cc17a324ae5c7dc</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "      <td>Hyōgo-ken</td>\n",
       "      <td>Kōbe-shi</td>\n",
       "      <td>Kumoidōri</td>\n",
       "      <td>17</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_fee8dcf4d619598e</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "      <td>Hyōgo-ken</td>\n",
       "      <td>Kōbe-shi</td>\n",
       "      <td>Kumoidōri</td>\n",
       "      <td>17</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_a17f0778617c76e2</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Hyōgo-ken Kōbe-shi Kumoidōri</td>\n",
       "      <td>34.695124</td>\n",
       "      <td>135.197852</td>\n",
       "      <td>Hyōgo-ken</td>\n",
       "      <td>Kōbe-shi</td>\n",
       "      <td>Kumoidōri</td>\n",
       "      <td>17</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_83db5aff8f50478e</td>\n",
       "      <td>Italian/French</td>\n",
       "      <td>Tōkyō-to Minato-ku Shibakōen</td>\n",
       "      <td>35.658068</td>\n",
       "      <td>139.751599</td>\n",
       "      <td>Tōkyō-to</td>\n",
       "      <td>Minato-ku</td>\n",
       "      <td>Shibakōen</td>\n",
       "      <td>51</td>\n",
       "      <td>444</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  air_genre_name                 air_area_name  \\\n",
       "0  air_0f0cdeee6c9bf3d7  Italian/French  Hyōgo-ken Kōbe-shi Kumoidōri   \n",
       "1  air_7cc17a324ae5c7dc  Italian/French  Hyōgo-ken Kōbe-shi Kumoidōri   \n",
       "2  air_fee8dcf4d619598e  Italian/French  Hyōgo-ken Kōbe-shi Kumoidōri   \n",
       "3  air_a17f0778617c76e2  Italian/French  Hyōgo-ken Kōbe-shi Kumoidōri   \n",
       "4  air_83db5aff8f50478e  Italian/French  Tōkyō-to Minato-ku Shibakōen   \n",
       "\n",
       "   latitude_air  longitude_air air_area_lv1 air_area_lv2 air_area_lv3  \\\n",
       "0     34.695124     135.197852    Hyōgo-ken     Kōbe-shi    Kumoidōri   \n",
       "1     34.695124     135.197852    Hyōgo-ken     Kōbe-shi    Kumoidōri   \n",
       "2     34.695124     135.197852    Hyōgo-ken     Kōbe-shi    Kumoidōri   \n",
       "3     34.695124     135.197852    Hyōgo-ken     Kōbe-shi    Kumoidōri   \n",
       "4     35.658068     139.751599     Tōkyō-to    Minato-ku    Shibakōen   \n",
       "\n",
       "   air_stores_on_same_addr  air_stores_lv1       ...         min_lat_hpg_lv1  \\\n",
       "0                       17              57       ...                     NaN   \n",
       "1                       17              57       ...                     NaN   \n",
       "2                       17              57       ...                     NaN   \n",
       "3                       17              57       ...                     NaN   \n",
       "4                       51             444       ...                     NaN   \n",
       "\n",
       "   mean_lon_hpg_lv1  max_lon_hpg_lv1  min_lon_hpg_lv1  mean_lat_hpg_lv2  \\\n",
       "0               NaN              NaN              NaN               NaN   \n",
       "1               NaN              NaN              NaN               NaN   \n",
       "2               NaN              NaN              NaN               NaN   \n",
       "3               NaN              NaN              NaN               NaN   \n",
       "4               NaN              NaN              NaN               NaN   \n",
       "\n",
       "   max_lat_hpg_lv2  min_lat_hpg_lv2  mean_lon_hpg_lv2  max_lon_hpg_lv2  \\\n",
       "0              NaN              NaN               NaN              NaN   \n",
       "1              NaN              NaN               NaN              NaN   \n",
       "2              NaN              NaN               NaN              NaN   \n",
       "3              NaN              NaN               NaN              NaN   \n",
       "4              NaN              NaN               NaN              NaN   \n",
       "\n",
       "   min_lon_hpg_lv2  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4              NaN  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "air_store_info = pd.merge(air_store_info, store_id_relation, how='left', on='air_store_id')\n",
    "air_store_info = pd.merge(air_store_info, hpg_store_info, how='left', on='hpg_store_id')\n",
    "air_store_info = air_store_info.rename(columns={'latitude_x':'latitude_air',\n",
    "                             'longitude_x':'longitude_air',\n",
    "                             'latitude_y':'latitude_hpg',\n",
    "                             'longitude_y':'longitude_hpg'})\n",
    "\n",
    "display(air_store_info.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add store information to full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>dow</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>doy</th>\n",
       "      <th>dom</th>\n",
       "      <th>woy</th>\n",
       "      <th>...</th>\n",
       "      <th>min_lat_hpg_lv1</th>\n",
       "      <th>mean_lon_hpg_lv1</th>\n",
       "      <th>max_lon_hpg_lv1</th>\n",
       "      <th>min_lon_hpg_lv1</th>\n",
       "      <th>mean_lat_hpg_lv2</th>\n",
       "      <th>max_lat_hpg_lv2</th>\n",
       "      <th>min_lat_hpg_lv2</th>\n",
       "      <th>mean_lon_hpg_lv2</th>\n",
       "      <th>max_lon_hpg_lv2</th>\n",
       "      <th>min_lon_hpg_lv2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id   id  visit_date  visitors  dow  year  month  doy  \\\n",
       "0  air_ba937bf13d40fb24  NaN  2016-01-13        25    2  2016      1   13   \n",
       "1  air_ba937bf13d40fb24  NaN  2016-01-14        32    3  2016      1   14   \n",
       "2  air_ba937bf13d40fb24  NaN  2016-01-15        29    4  2016      1   15   \n",
       "3  air_ba937bf13d40fb24  NaN  2016-01-16        22    5  2016      1   16   \n",
       "4  air_ba937bf13d40fb24  NaN  2016-01-18         6    0  2016      1   18   \n",
       "\n",
       "   dom  woy       ...         min_lat_hpg_lv1  mean_lon_hpg_lv1  \\\n",
       "0   31    2       ...                     NaN               NaN   \n",
       "1   31    2       ...                     NaN               NaN   \n",
       "2   31    2       ...                     NaN               NaN   \n",
       "3   31    2       ...                     NaN               NaN   \n",
       "4   31    3       ...                     NaN               NaN   \n",
       "\n",
       "  max_lon_hpg_lv1 min_lon_hpg_lv1  mean_lat_hpg_lv2  max_lat_hpg_lv2  \\\n",
       "0             NaN             NaN               NaN              NaN   \n",
       "1             NaN             NaN               NaN              NaN   \n",
       "2             NaN             NaN               NaN              NaN   \n",
       "3             NaN             NaN               NaN              NaN   \n",
       "4             NaN             NaN               NaN              NaN   \n",
       "\n",
       "  min_lat_hpg_lv2 mean_lon_hpg_lv2 max_lon_hpg_lv2  min_lon_hpg_lv2  \n",
       "0             NaN              NaN             NaN              NaN  \n",
       "1             NaN              NaN             NaN              NaN  \n",
       "2             NaN              NaN             NaN              NaN  \n",
       "3             NaN              NaN             NaN              NaN  \n",
       "4             NaN              NaN             NaN              NaN  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_data = pd.merge(full_data, air_store_info, how='left', on='air_store_id')\n",
    "display(full_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reservation information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_datetime</th>\n",
       "      <th>reserve_datetime</th>\n",
       "      <th>reserve_visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_877f79706adbfb06</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>2016-01-01 16:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_db4b38ebe7a7ceff</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_db4b38ebe7a7ceff</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_877f79706adbfb06</td>\n",
       "      <td>2016-01-01 20:00:00</td>\n",
       "      <td>2016-01-01 16:00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_db80363d35f10926</td>\n",
       "      <td>2016-01-01 20:00:00</td>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id       visit_datetime     reserve_datetime  \\\n",
       "0  air_877f79706adbfb06  2016-01-01 19:00:00  2016-01-01 16:00:00   \n",
       "1  air_db4b38ebe7a7ceff  2016-01-01 19:00:00  2016-01-01 19:00:00   \n",
       "2  air_db4b38ebe7a7ceff  2016-01-01 19:00:00  2016-01-01 19:00:00   \n",
       "3  air_877f79706adbfb06  2016-01-01 20:00:00  2016-01-01 16:00:00   \n",
       "4  air_db80363d35f10926  2016-01-01 20:00:00  2016-01-01 01:00:00   \n",
       "\n",
       "   reserve_visitors  \n",
       "0                 1  \n",
       "1                 3  \n",
       "2                 6  \n",
       "3                 2  \n",
       "4                 5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hpg_store_id</th>\n",
       "      <th>visit_datetime</th>\n",
       "      <th>reserve_datetime</th>\n",
       "      <th>reserve_visitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpg_c63f6f42e088e50f</td>\n",
       "      <td>2016-01-01 11:00:00</td>\n",
       "      <td>2016-01-01 09:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hpg_dac72789163a3f47</td>\n",
       "      <td>2016-01-01 13:00:00</td>\n",
       "      <td>2016-01-01 06:00:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hpg_c8e24dcf51ca1eb5</td>\n",
       "      <td>2016-01-01 16:00:00</td>\n",
       "      <td>2016-01-01 14:00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hpg_24bb207e5fd49d4a</td>\n",
       "      <td>2016-01-01 17:00:00</td>\n",
       "      <td>2016-01-01 11:00:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hpg_25291c542ebb3bc2</td>\n",
       "      <td>2016-01-01 17:00:00</td>\n",
       "      <td>2016-01-01 03:00:00</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           hpg_store_id       visit_datetime     reserve_datetime  \\\n",
       "0  hpg_c63f6f42e088e50f  2016-01-01 11:00:00  2016-01-01 09:00:00   \n",
       "1  hpg_dac72789163a3f47  2016-01-01 13:00:00  2016-01-01 06:00:00   \n",
       "2  hpg_c8e24dcf51ca1eb5  2016-01-01 16:00:00  2016-01-01 14:00:00   \n",
       "3  hpg_24bb207e5fd49d4a  2016-01-01 17:00:00  2016-01-01 11:00:00   \n",
       "4  hpg_25291c542ebb3bc2  2016-01-01 17:00:00  2016-01-01 03:00:00   \n",
       "\n",
       "   reserve_visitors  \n",
       "0                 1  \n",
       "1                 3  \n",
       "2                 2  \n",
       "3                 5  \n",
       "4                13  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_datetime</th>\n",
       "      <th>reserve_datetime</th>\n",
       "      <th>reserve_visitors</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>reserve_date</th>\n",
       "      <th>reserve_datetime_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_877f79706adbfb06</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>2016-01-01 16:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_db4b38ebe7a7ceff</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_db4b38ebe7a7ceff</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>2016-01-01 19:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_877f79706adbfb06</td>\n",
       "      <td>2016-01-01 20:00:00</td>\n",
       "      <td>2016-01-01 16:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_db80363d35f10926</td>\n",
       "      <td>2016-01-01 20:00:00</td>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>3.958333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id      visit_datetime    reserve_datetime  \\\n",
       "0  air_877f79706adbfb06 2016-01-01 19:00:00 2016-01-01 16:00:00   \n",
       "1  air_db4b38ebe7a7ceff 2016-01-01 19:00:00 2016-01-01 19:00:00   \n",
       "2  air_db4b38ebe7a7ceff 2016-01-01 19:00:00 2016-01-01 19:00:00   \n",
       "3  air_877f79706adbfb06 2016-01-01 20:00:00 2016-01-01 16:00:00   \n",
       "4  air_db80363d35f10926 2016-01-01 20:00:00 2016-01-01 01:00:00   \n",
       "\n",
       "   reserve_visitors  visit_date reserve_date  reserve_datetime_diff  \n",
       "0                 1  2016-01-01   2016-01-01               0.125000  \n",
       "1                 3  2016-01-01   2016-01-01               0.000000  \n",
       "2                 6  2016-01-01   2016-01-01               0.000000  \n",
       "3                 2  2016-01-01   2016-01-01               0.333333  \n",
       "4                 5  2016-01-01   2016-01-01               3.958333  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hpg_store_id</th>\n",
       "      <th>visit_datetime</th>\n",
       "      <th>reserve_datetime</th>\n",
       "      <th>reserve_visitors</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>reserve_date</th>\n",
       "      <th>reserve_datetime_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpg_c63f6f42e088e50f</td>\n",
       "      <td>2016-01-01 11:00:00</td>\n",
       "      <td>2016-01-01 09:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hpg_dac72789163a3f47</td>\n",
       "      <td>2016-01-01 13:00:00</td>\n",
       "      <td>2016-01-01 06:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hpg_c8e24dcf51ca1eb5</td>\n",
       "      <td>2016-01-01 16:00:00</td>\n",
       "      <td>2016-01-01 14:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hpg_24bb207e5fd49d4a</td>\n",
       "      <td>2016-01-01 17:00:00</td>\n",
       "      <td>2016-01-01 11:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hpg_25291c542ebb3bc2</td>\n",
       "      <td>2016-01-01 17:00:00</td>\n",
       "      <td>2016-01-01 03:00:00</td>\n",
       "      <td>13</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>7.583333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           hpg_store_id      visit_datetime    reserve_datetime  \\\n",
       "0  hpg_c63f6f42e088e50f 2016-01-01 11:00:00 2016-01-01 09:00:00   \n",
       "1  hpg_dac72789163a3f47 2016-01-01 13:00:00 2016-01-01 06:00:00   \n",
       "2  hpg_c8e24dcf51ca1eb5 2016-01-01 16:00:00 2016-01-01 14:00:00   \n",
       "3  hpg_24bb207e5fd49d4a 2016-01-01 17:00:00 2016-01-01 11:00:00   \n",
       "4  hpg_25291c542ebb3bc2 2016-01-01 17:00:00 2016-01-01 03:00:00   \n",
       "\n",
       "   reserve_visitors  visit_date reserve_date  reserve_datetime_diff  \n",
       "0                 1  2016-01-01   2016-01-01               0.083333  \n",
       "1                 3  2016-01-01   2016-01-01               0.875000  \n",
       "2                 2  2016-01-01   2016-01-01               0.166667  \n",
       "3                 5  2016-01-01   2016-01-01               1.250000  \n",
       "4                13  2016-01-01   2016-01-01               7.583333  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print ('before')\n",
    "display(air_reserve.head())\n",
    "display(hpg_reserve.head())\n",
    "\n",
    "air_reserve['visit_date'] = air_reserve['visit_datetime'].apply(lambda x:x[:10])\n",
    "air_reserve['reserve_date'] = air_reserve['reserve_datetime'].apply(lambda x:x[:10])\n",
    "air_reserve['reserve_datetime'] = pd.to_datetime(air_reserve['reserve_datetime'])\n",
    "air_reserve['reserve_date'] = air_reserve['reserve_datetime'].dt.date\n",
    "air_reserve['visit_datetime'] = pd.to_datetime(air_reserve['visit_datetime'])\n",
    "air_reserve['visit_date'] = air_reserve['visit_datetime'].dt.date\n",
    "air_reserve['reserve_datetime_diff'] = air_reserve.apply(lambda r: (r['visit_datetime'] - r['reserve_datetime']).seconds \n",
    "                                                         * r['reserve_visitors']/3600/24.0, axis=1)\n",
    "\n",
    "\n",
    "hpg_reserve['visit_date'] = hpg_reserve['visit_datetime'].apply(lambda x:x[:10])\n",
    "hpg_reserve['reserve_date'] = hpg_reserve['reserve_datetime'].apply(lambda x:x[:10])\n",
    "hpg_reserve['reserve_datetime'] = pd.to_datetime(hpg_reserve['reserve_datetime'])\n",
    "hpg_reserve['reserve_date'] = hpg_reserve['reserve_datetime'].dt.date\n",
    "hpg_reserve['visit_datetime'] = pd.to_datetime(hpg_reserve['visit_datetime'])\n",
    "hpg_reserve['visit_date'] = hpg_reserve['visit_datetime'].dt.date\n",
    "hpg_reserve['reserve_datetime_diff'] = hpg_reserve.apply(lambda r: (r['visit_datetime'] - r['reserve_datetime']).seconds\n",
    "                                                         * r['reserve_visitors']/3600/24.0, axis=1)\n",
    "\n",
    "print ('after')\n",
    "display(air_reserve.head())\n",
    "display(hpg_reserve.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregate reservations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>air_rvs</th>\n",
       "      <th>air_rv_dt_diff</th>\n",
       "      <th>mean_air_rv_dt_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-10-31</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-12-05</td>\n",
       "      <td>9</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-12-14</td>\n",
       "      <td>18</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-12-17</td>\n",
       "      <td>2</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_00a91d42b08b08d9</td>\n",
       "      <td>2016-12-20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id  visit_date  air_rvs  air_rv_dt_diff  \\\n",
       "0  air_00a91d42b08b08d9  2016-10-31        2        0.333333   \n",
       "1  air_00a91d42b08b08d9  2016-12-05        9        1.500000   \n",
       "2  air_00a91d42b08b08d9  2016-12-14       18        6.750000   \n",
       "3  air_00a91d42b08b08d9  2016-12-17        2        0.250000   \n",
       "4  air_00a91d42b08b08d9  2016-12-20        4        0.500000   \n",
       "\n",
       "   mean_air_rv_dt_diff  \n",
       "0             0.166667  \n",
       "1             0.166667  \n",
       "2             0.375000  \n",
       "3             0.125000  \n",
       "4             0.125000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hpg_store_id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>hpg_rvs</th>\n",
       "      <th>hpg_rv_dt_diff</th>\n",
       "      <th>mean_hpg_rv_dt_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hpg_001112ef76b9802c</td>\n",
       "      <td>2016-02-26</td>\n",
       "      <td>9</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hpg_001112ef76b9802c</td>\n",
       "      <td>2016-03-17</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hpg_001112ef76b9802c</td>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>5</td>\n",
       "      <td>4.791667</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hpg_001112ef76b9802c</td>\n",
       "      <td>2016-04-05</td>\n",
       "      <td>13</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hpg_001112ef76b9802c</td>\n",
       "      <td>2016-04-18</td>\n",
       "      <td>9</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>0.208333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           hpg_store_id  visit_date  hpg_rvs  hpg_rv_dt_diff  \\\n",
       "0  hpg_001112ef76b9802c  2016-02-26        9        2.250000   \n",
       "1  hpg_001112ef76b9802c  2016-03-17        3        0.000000   \n",
       "2  hpg_001112ef76b9802c  2016-03-31        5        4.791667   \n",
       "3  hpg_001112ef76b9802c  2016-04-05       13        4.333333   \n",
       "4  hpg_001112ef76b9802c  2016-04-18        9        1.875000   \n",
       "\n",
       "   mean_hpg_rv_dt_diff  \n",
       "0             0.250000  \n",
       "1             0.000000  \n",
       "2             0.958333  \n",
       "3             0.333333  \n",
       "4             0.208333  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "air_reserve_grp = air_reserve.groupby(['air_store_id','visit_date'])['reserve_visitors','reserve_datetime_diff'].\\\n",
    "            sum().reset_index().rename(columns={'reserve_visitors':'air_rvs',\n",
    "                                               'reserve_datetime_diff':'air_rv_dt_diff'})\n",
    "hpg_reserve_grp = hpg_reserve.groupby(['hpg_store_id','visit_date'])['reserve_visitors','reserve_datetime_diff'].\\\n",
    "            sum().reset_index().rename(columns={'reserve_visitors':'hpg_rvs',\n",
    "                                               'reserve_datetime_diff':'hpg_rv_dt_diff'})\n",
    "air_reserve_grp['mean_air_rv_dt_diff'] = air_reserve_grp.air_rv_dt_diff / air_reserve_grp.air_rvs\n",
    "hpg_reserve_grp['mean_hpg_rv_dt_diff'] = hpg_reserve_grp.hpg_rv_dt_diff / hpg_reserve_grp.hpg_rvs    \n",
    "    \n",
    "display(air_reserve_grp.head())\n",
    "display(hpg_reserve_grp.head())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add reservations to full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>dow</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>doy</th>\n",
       "      <th>dom</th>\n",
       "      <th>woy</th>\n",
       "      <th>...</th>\n",
       "      <th>min_lat_hpg_lv2</th>\n",
       "      <th>mean_lon_hpg_lv2</th>\n",
       "      <th>max_lon_hpg_lv2</th>\n",
       "      <th>min_lon_hpg_lv2</th>\n",
       "      <th>air_rvs</th>\n",
       "      <th>air_rv_dt_diff</th>\n",
       "      <th>mean_air_rv_dt_diff</th>\n",
       "      <th>hpg_rvs</th>\n",
       "      <th>hpg_rv_dt_diff</th>\n",
       "      <th>mean_hpg_rv_dt_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4669</th>\n",
       "      <td>air_3e93f3c81008696d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-10-27</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>301</td>\n",
       "      <td>31</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.083333</td>\n",
       "      <td>0.590278</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4670</th>\n",
       "      <td>air_3e93f3c81008696d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-10-28</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>302</td>\n",
       "      <td>31</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4671</th>\n",
       "      <td>air_3e93f3c81008696d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>303</td>\n",
       "      <td>31</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>28.0</td>\n",
       "      <td>18.416667</td>\n",
       "      <td>0.657738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4673</th>\n",
       "      <td>air_3e93f3c81008696d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-11-01</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>306</td>\n",
       "      <td>30</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.0</td>\n",
       "      <td>66.250000</td>\n",
       "      <td>0.895270</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4676</th>\n",
       "      <td>air_3e93f3c81008696d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-11-04</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>11</td>\n",
       "      <td>309</td>\n",
       "      <td>30</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.625000</td>\n",
       "      <td>0.420455</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              air_store_id   id  visit_date  visitors  dow  year  month  doy  \\\n",
       "4669  air_3e93f3c81008696d  NaN  2016-10-27        48    3  2016     10  301   \n",
       "4670  air_3e93f3c81008696d  NaN  2016-10-28        25    4  2016     10  302   \n",
       "4671  air_3e93f3c81008696d  NaN  2016-10-29        42    5  2016     10  303   \n",
       "4673  air_3e93f3c81008696d  NaN  2016-11-01        76    1  2016     11  306   \n",
       "4676  air_3e93f3c81008696d  NaN  2016-11-04         5    4  2016     11  309   \n",
       "\n",
       "      dom  woy         ...           min_lat_hpg_lv2  mean_lon_hpg_lv2  \\\n",
       "4669   31   43         ...                       NaN               NaN   \n",
       "4670   31   43         ...                       NaN               NaN   \n",
       "4671   31   43         ...                       NaN               NaN   \n",
       "4673   30   44         ...                       NaN               NaN   \n",
       "4676   30   44         ...                       NaN               NaN   \n",
       "\n",
       "     max_lon_hpg_lv2 min_lon_hpg_lv2  air_rvs  air_rv_dt_diff  \\\n",
       "4669             NaN             NaN     12.0        7.083333   \n",
       "4670             NaN             NaN      4.0        1.833333   \n",
       "4671             NaN             NaN     17.0       13.000000   \n",
       "4673             NaN             NaN     74.0       66.250000   \n",
       "4676             NaN             NaN     11.0        4.625000   \n",
       "\n",
       "     mean_air_rv_dt_diff hpg_rvs hpg_rv_dt_diff  mean_hpg_rv_dt_diff  \n",
       "4669            0.590278     2.0       1.750000             0.875000  \n",
       "4670            0.458333     2.0       1.833333             0.916667  \n",
       "4671            0.764706    28.0      18.416667             0.657738  \n",
       "4673            0.895270     3.0       2.625000             0.875000  \n",
       "4676            0.420455     7.0       2.625000             0.375000  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_data = pd.merge(full_data, air_reserve_grp, how='left', on=['air_store_id','visit_date'])\n",
    "full_data = pd.merge(full_data, hpg_reserve_grp, how='left', on=['hpg_store_id','visit_date'])\n",
    "\n",
    "display(full_data.query('air_rvs>0 and hpg_rvs>0').head()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date infomation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visit_date</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>holiday_flg</th>\n",
       "      <th>dow</th>\n",
       "      <th>date_len</th>\n",
       "      <th>date_index</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Friday</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>517</td>\n",
       "      <td>1</td>\n",
       "      <td>2.707368e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>517</td>\n",
       "      <td>2</td>\n",
       "      <td>8.663577e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>517</td>\n",
       "      <td>3</td>\n",
       "      <td>6.578904e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>517</td>\n",
       "      <td>4</td>\n",
       "      <td>2.772345e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>517</td>\n",
       "      <td>5</td>\n",
       "      <td>8.460525e-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   visit_date day_of_week  holiday_flg  dow  date_len  date_index  \\\n",
       "0  2016-01-01      Friday            1    4       517           1   \n",
       "1  2016-01-02    Saturday            1    5       517           2   \n",
       "2  2016-01-03      Sunday            1    6       517           3   \n",
       "3  2016-01-04      Monday            0    0       517           4   \n",
       "4  2016-01-05     Tuesday            0    1       517           5   \n",
       "\n",
       "         weight  \n",
       "0  2.707368e-14  \n",
       "1  8.663577e-13  \n",
       "2  6.578904e-12  \n",
       "3  2.772345e-11  \n",
       "4  8.460525e-11  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_info['visit_date'] = pd.to_datetime(date_info['visit_date'])\n",
    "date_info['dow'] = date_info['visit_date'].dt.dayofweek\n",
    "date_info['date_len'] = len(date_info)\n",
    "date_info['date_index'] = date_info.index + 1\n",
    "date_info['weight'] = ((date_info.index + 1) / len(date_info)) ** 5  \n",
    "date_info['visit_date'] = date_info['visit_date'].dt.date\n",
    "date_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_data = pd.merge(full_data, date_info[['visit_date','date_len','date_index','weight', 'holiday_flg']], \n",
    "                     how='left', on='visit_date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_vars = ['dow', 'year', 'month', 'doy', 'dom', 'woy', 'holiday_flg',\n",
    "            'date_index', 'date_int', 'air_stores_on_same_addr', 'hpg_stores_on_same_addr',\n",
    "            'latitude_air', 'longitude_air', \n",
    "            'air_stores_on_same_addr', 'air_stores_lv1', 'air_stores_lv2',\n",
    "            'mean_lat_air_lv1', 'max_lat_air_lv1', 'min_lat_air_lv1',\n",
    "            'mean_lon_air_lv1', 'max_lon_air_lv1', 'min_lon_air_lv1',\n",
    "            'mean_lat_air_lv2', 'max_lat_air_lv2', 'min_lat_air_lv2',\n",
    "            'mean_lon_air_lv2', 'max_lon_air_lv2', 'min_lon_air_lv2',\n",
    "            'latitude_hpg', 'longitude_hpg', \n",
    "            'hpg_stores_on_same_addr', 'hpg_stores_lv1', 'hpg_stores_lv2',\n",
    "            'mean_lat_hpg_lv1', 'max_lat_hpg_lv1', 'min_lat_hpg_lv1',\n",
    "            'mean_lon_hpg_lv1', 'max_lon_hpg_lv1', 'min_lon_hpg_lv1',\n",
    "            'mean_lat_hpg_lv2', 'max_lat_hpg_lv2', 'min_lat_hpg_lv2',\n",
    "            'mean_lon_hpg_lv2', 'max_lon_hpg_lv2', 'min_lon_hpg_lv2',\n",
    "            'air_rvs', 'hpg_rvs','air_rv_dt_diff', 'hpg_rv_dt_diff']\n",
    "\n",
    "\n",
    "cat_vars = ['air_store_id', 'air_genre_name', 'air_area_name', 'air_area_lv1', 'air_area_lv2', 'air_area_lv3',\n",
    "            'hpg_store_id', 'hpg_genre_name', 'hpg_area_name', 'hpg_area_lv1', 'hpg_area_lv2', 'hpg_area_lv3']\n",
    "\n",
    "id_var = 'air_store_id'\n",
    "target_var = 'visitors'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing value imputation\n",
    "\n",
    "For this week we will leave missing values(Nan) as is and let XGBoost to take care of them automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Categorical features - label encoding\n",
    "\n",
    "Label encoding is not really necessary for this competition as all categorical features have already been digitalized. I'm including this just for your reference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding air_store_id\n",
      "Label Encoding air_genre_name\n",
      "Label Encoding air_area_name\n",
      "Label Encoding air_area_lv1\n",
      "Label Encoding air_area_lv2\n",
      "Label Encoding air_area_lv3\n",
      "Label Encoding hpg_store_id\n",
      "Label Encoding hpg_genre_name\n",
      "Label Encoding hpg_area_name\n",
      "Label Encoding hpg_area_lv1\n",
      "Label Encoding hpg_area_lv2\n",
      "Label Encoding hpg_area_lv3\n",
      "Label-encoded feaures: ['air_store_id_le', 'air_genre_name_le', 'air_area_name_le', 'air_area_lv1_le', 'air_area_lv2_le', 'air_area_lv3_le', 'hpg_store_id_le', 'hpg_genre_name_le', 'hpg_area_name_le', 'hpg_area_lv1_le', 'hpg_area_lv2_le', 'hpg_area_lv3_le']\n"
     ]
    }
   ],
   "source": [
    "LBL = preprocessing.LabelEncoder()\n",
    "\n",
    "LE_vars=[]\n",
    "LE_map=dict()\n",
    "for cat_var in cat_vars:\n",
    "    print (\"Label Encoding %s\" % (cat_var))\n",
    "    LE_var=cat_var+'_le'\n",
    "    full_data[LE_var]=LBL.fit_transform(full_data[cat_var].astype(str))\n",
    "    LE_vars.append(LE_var)\n",
    "    LE_map[cat_var]=LBL.classes_\n",
    "    \n",
    "print (\"Label-encoded feaures: %s\" % (LE_vars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical features - one hot encoding¶\n",
    "\n",
    "You don't want to concatenate the converted OHE features with the original dataframe(full_data) becuase it would exponentially enlarge the size of the dataframe. In fact, it's recommended to use scipy.sparse.hstack to concatenate the data which you will see in the following sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot-encoding finished in 1.153341 seconds\n",
      "OHE_sparse size : (284127, 1377)\n",
      "One-hot encoded catgorical feature samples : ['air_store_air_00a91d42b08b08d9', 'air_store_air_0164b9927d20bcc3', 'air_store_air_0241aa3964b7f861', 'air_store_air_0328696196e46f18', 'air_store_air_034a3d5b40d5b1b1', 'air_store_air_036d4f1ee7285390', 'air_store_air_0382c794b73b51ad', 'air_store_air_03963426c9312048', 'air_store_air_04341b588bde96cd', 'air_store_air_049f6d5b402a31b2', 'air_store_air_04cae7c1bc9b2a0b', 'air_store_air_0585011fa179bcce', 'air_store_air_05c325d315cc17f5', 'air_store_air_0647f17b4dc041c8', 'air_store_air_064e203265ee5753', 'air_store_air_066f0221b8a4d533', 'air_store_air_06f95ac5c33aca10', 'air_store_air_0728814bd98f7367', 'air_store_air_0768ab3910f7967f', 'air_store_air_07b314d83059c4d2', 'air_store_air_07bb665f9cdfbdfb', 'air_store_air_082908692355165e', 'air_store_air_083ddc520ea47e1e', 'air_store_air_0845d8395f30c6bb', 'air_store_air_084d98859256acf0', 'air_store_air_0867f7bebad6a649', 'air_store_air_08ba8cd01b3ba010', 'air_store_air_08cb3c4ee6cd6a22', 'air_store_air_08ef81d5b7a0d13f', 'air_store_air_08f994758a1e76d4', 'air_store_air_09040f6df960ddb8', 'air_store_air_0919d54f0c9a24b8', 'air_store_air_09661c0f3259cc04', 'air_store_air_09a845d5b5944b01', 'air_store_air_09fd1f5c58583141', 'air_store_air_0a74a5408a0b8642', 'air_store_air_0b184ec04c741a6a', 'air_store_air_0b1e72d2d4422b20', 'air_store_air_0b9038300f8b2b50', 'air_store_air_0e1eae99b8723bc1', 'air_store_air_0e7c11b9abc50163', 'air_store_air_0ead98dd07e7a82a', 'air_store_air_0f0cdeee6c9bf3d7', 'air_store_air_0f2f96335f274801', 'air_store_air_0f60e1576a7d397d', 'air_store_air_1033310359ceeac1', 'air_store_air_10393f12e9069760', 'air_store_air_105a7954e32dba9b', 'air_store_air_10713fbf3071c361', 'air_store_air_10bbe8acd943d8f6', 'air_store_air_12c4fb7a423df20d', 'air_store_air_138ee734ac79ff90', 'air_store_air_138ff410757b845f', 'air_store_air_1408dd53f31a8a65', 'air_store_air_142e78ba7001da9c', 'air_store_air_1509881b22965b34', 'air_store_air_152c1f08d7d20e07', 'air_store_air_15ae33469e9ea2dd', 'air_store_air_15e6e15c7ea2c162', 'air_store_air_16179d43b6ee5fd8', 'air_store_air_1653a6c513865af3', 'air_store_air_168441ada3e878e1', 'air_store_air_16c4cfddeb2cf69b', 'air_store_air_16cf0a73233896de', 'air_store_air_1707a3f18bb0da07', 'air_store_air_17a6ab40f97fd4d8', 'air_store_air_17bed6dbf7c8b0fc', 'air_store_air_1979eaff8189d086', 'air_store_air_1ab60ce33bfed8a8', 'air_store_air_1ae94f514a0bce13', 'air_store_air_1ba4e87ef7422183', 'air_store_air_1c0b150f9e696a5f', 'air_store_air_1c95a84924d72500', 'air_store_air_1d1e8860ae04f8e9', 'air_store_air_1d25ca6c76df48b4', 'air_store_air_1d3f797dd1f7cf1c', 'air_store_air_1dd8f6f47480d1a2', 'air_store_air_1dea9815ccd36620', 'air_store_air_1e23210b584540e7', 'air_store_air_1e665503b8474c55', 'air_store_air_1eeff462acb24fb7', 'air_store_air_1f1390a8be2272b3', 'air_store_air_1f34e9beded2231a', 'air_store_air_1f7f8fa557bc0d55', 'air_store_air_2009041dbf9264de', 'air_store_air_20619d21192aa571', 'air_store_air_20add8092c9bb51d', 'air_store_air_2195cd5025a98033', 'air_store_air_21f5052d5330528d', 'air_store_air_220cba70c890b119', 'air_store_air_22682e965418936f', 'air_store_air_228f10bec0bda9c8', 'air_store_air_229d7e508d9f1b5e', 'air_store_air_232dcee6f7c51d37', 'air_store_air_234d3dbf7f3d5a50', 'air_store_air_23e1b11aee2a1407', 'air_store_air_23ee674e91469086', 'air_store_air_24b9b2a020826ede', 'air_store_air_24e8414b9b07decb', 'air_store_air_2545dd3a00f265e2']\n"
     ]
    }
   ],
   "source": [
    "OHE = preprocessing.OneHotEncoder(sparse=True)\n",
    "start=time.time()\n",
    "OHE.fit(full_data[LE_vars])\n",
    "OHE_sparse=OHE.transform(full_data[LE_vars])\n",
    "                                   \n",
    "print ('One-hot-encoding finished in %f seconds' % (time.time()-start))\n",
    "\n",
    "\n",
    "OHE_vars = [var[:-3] + '_' + str(level).replace(' ','_')\\\n",
    "                for var in cat_vars for level in LE_map[var] ]\n",
    "\n",
    "print (\"OHE_sparse size :\" ,OHE_sparse.shape)\n",
    "print (\"One-hot encoded catgorical feature samples : %s\" % (OHE_vars[:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric features\n",
    "\n",
    "For week 1 and week 2 we will be using XGBoost/LightGBM which typically don't require pre-processing for numeric features so we will skip this part until week 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature interactions\n",
    "### numeric to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_store_id</th>\n",
       "      <th>id</th>\n",
       "      <th>visit_date</th>\n",
       "      <th>visitors</th>\n",
       "      <th>dow</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>doy</th>\n",
       "      <th>dom</th>\n",
       "      <th>woy</th>\n",
       "      <th>...</th>\n",
       "      <th>lat_to_min_lat_hpg_lv1</th>\n",
       "      <th>lon_to_mean_lon_hpg_lv1</th>\n",
       "      <th>lon_to_max_lon_hpg_lv1</th>\n",
       "      <th>lon_to_min_lon_hpg_lv1</th>\n",
       "      <th>lat_to_mean_lat_hpg_lv2</th>\n",
       "      <th>lat_to_max_lat_hpg_lv2</th>\n",
       "      <th>lat_to_min_lat_hpg_lv2</th>\n",
       "      <th>lon_to_mean_lon_hpg_lv2</th>\n",
       "      <th>lon_to_max_lon_hpg_lv2</th>\n",
       "      <th>lon_to_min_lon_hpg_lv2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-13</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-14</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-16</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air_ba937bf13d40fb24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           air_store_id   id  visit_date  visitors  dow  year  month  doy  \\\n",
       "0  air_ba937bf13d40fb24  NaN  2016-01-13        25    2  2016      1   13   \n",
       "1  air_ba937bf13d40fb24  NaN  2016-01-14        32    3  2016      1   14   \n",
       "2  air_ba937bf13d40fb24  NaN  2016-01-15        29    4  2016      1   15   \n",
       "3  air_ba937bf13d40fb24  NaN  2016-01-16        22    5  2016      1   16   \n",
       "4  air_ba937bf13d40fb24  NaN  2016-01-18         6    0  2016      1   18   \n",
       "\n",
       "   dom  woy           ...            lat_to_min_lat_hpg_lv1  \\\n",
       "0   31    2           ...                               NaN   \n",
       "1   31    2           ...                               NaN   \n",
       "2   31    2           ...                               NaN   \n",
       "3   31    2           ...                               NaN   \n",
       "4   31    3           ...                               NaN   \n",
       "\n",
       "   lon_to_mean_lon_hpg_lv1 lon_to_max_lon_hpg_lv1 lon_to_min_lon_hpg_lv1  \\\n",
       "0                      NaN                    NaN                    NaN   \n",
       "1                      NaN                    NaN                    NaN   \n",
       "2                      NaN                    NaN                    NaN   \n",
       "3                      NaN                    NaN                    NaN   \n",
       "4                      NaN                    NaN                    NaN   \n",
       "\n",
       "   lat_to_mean_lat_hpg_lv2  lat_to_max_lat_hpg_lv2 lat_to_min_lat_hpg_lv2  \\\n",
       "0                      NaN                     NaN                    NaN   \n",
       "1                      NaN                     NaN                    NaN   \n",
       "2                      NaN                     NaN                    NaN   \n",
       "3                      NaN                     NaN                    NaN   \n",
       "4                      NaN                     NaN                    NaN   \n",
       "\n",
       "  lon_to_mean_lon_hpg_lv2 lon_to_max_lon_hpg_lv2  lon_to_min_lon_hpg_lv2  \n",
       "0                     NaN                    NaN                     NaN  \n",
       "1                     NaN                    NaN                     NaN  \n",
       "2                     NaN                    NaN                     NaN  \n",
       "3                     NaN                    NaN                     NaN  \n",
       "4                     NaN                    NaN                     NaN  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data['total_rvs'] = full_data['air_rvs'] + full_data['hpg_rvs']\n",
    "full_data['mean_rvs_air_hpg'] = full_data[['air_rvs','hpg_rvs']].apply(lambda x:np.mean(x), axis=1)\n",
    "full_data['mean_dt_diff_air_hpg'] = full_data[['air_rv_dt_diff','hpg_rv_dt_diff']].apply(lambda x:np.mean(x), axis=1)\n",
    "\n",
    "# NEW FEATURES FROM Georgii Vyshnia\n",
    "full_data['lon_plus_lat_air'] = full_data['longitude_air'] + full_data['latitude_air'] \n",
    "\n",
    "full_data['lat_to_mean_lat_air_lv1'] = abs(full_data['latitude_air']-full_data['mean_lat_air_lv1'])\n",
    "full_data['lat_to_max_lat_air_lv1']  = full_data['latitude_air']-full_data['max_lat_air_lv1']\n",
    "full_data['lat_to_min_lat_air_lv1']  = full_data['latitude_air']-full_data['min_lat_air_lv1']\n",
    "full_data['lon_to_mean_lon_air_lv1']  = abs(full_data['longitude_air']-full_data['mean_lon_air_lv1'])\n",
    "full_data['lon_to_max_lon_air_lv1']  = full_data['longitude_air']-full_data['max_lon_air_lv1']\n",
    "full_data['lon_to_min_lon_air_lv1']  = full_data['longitude_air']-full_data['min_lon_air_lv1']\n",
    "full_data['lat_to_mean_lat_air_lv2'] = abs(full_data['latitude_air']-full_data['mean_lat_air_lv2'])\n",
    "full_data['lat_to_max_lat_air_lv2']  = full_data['latitude_air']-full_data['max_lat_air_lv2']\n",
    "full_data['lat_to_min_lat_air_lv2']  = full_data['latitude_air']-full_data['min_lat_air_lv2']\n",
    "full_data['lon_to_mean_lon_air_lv2'] = abs(full_data['longitude_air']-full_data['mean_lon_air_lv2'])\n",
    "full_data['lon_to_max_lon_air_lv2']  = full_data['longitude_air']-full_data['max_lon_air_lv2']\n",
    "full_data['lon_to_min_lon_air_lv2']  = full_data['longitude_air']-full_data['min_lon_air_lv2']\n",
    "\n",
    "full_data['lat_to_mean_lat_hpg_lv1'] = abs(full_data['latitude_hpg']-full_data['mean_lat_hpg_lv1'])\n",
    "full_data['lat_to_max_lat_hpg_lv1']  = full_data['latitude_hpg']-full_data['max_lat_hpg_lv1']\n",
    "full_data['lat_to_min_lat_hpg_lv1']  = full_data['latitude_hpg']-full_data['min_lat_hpg_lv1']\n",
    "full_data['lon_to_mean_lon_hpg_lv1']  = abs(full_data['longitude_hpg']-full_data['mean_lon_hpg_lv1'])\n",
    "full_data['lon_to_max_lon_hpg_lv1']  = full_data['longitude_hpg']-full_data['max_lon_hpg_lv1']\n",
    "full_data['lon_to_min_lon_hpg_lv1']  = full_data['longitude_hpg']-full_data['min_lon_hpg_lv1']\n",
    "full_data['lat_to_mean_lat_hpg_lv2'] = abs(full_data['latitude_hpg']-full_data['mean_lat_hpg_lv2'])\n",
    "full_data['lat_to_max_lat_hpg_lv2']  = full_data['latitude_hpg']-full_data['max_lat_hpg_lv2']\n",
    "full_data['lat_to_min_lat_hpg_lv2']  = full_data['latitude_hpg']-full_data['min_lat_hpg_lv2']\n",
    "full_data['lon_to_mean_lon_hpg_lv2'] = abs(full_data['longitude_hpg']-full_data['mean_lon_hpg_lv2'])\n",
    "full_data['lon_to_max_lon_hpg_lv2']  = full_data['longitude_hpg']-full_data['max_lon_hpg_lv2']\n",
    "full_data['lon_to_min_lon_hpg_lv2']  = full_data['longitude_hpg']-full_data['min_lon_hpg_lv2']\n",
    "\n",
    "num_num_vars = ['total_rvs', 'mean_rvs_air_hpg',\n",
    "       'mean_dt_diff_air_hpg', 'lon_plus_lat_air',\n",
    "       'lat_to_mean_lat_air_lv1', 'lat_to_max_lat_air_lv1',\n",
    "       'lat_to_min_lat_air_lv1', 'lon_to_mean_lon_air_lv1',\n",
    "       'lon_to_max_lon_air_lv1', 'lon_to_min_lon_air_lv1',\n",
    "       'lat_to_mean_lat_air_lv2', 'lat_to_max_lat_air_lv2',\n",
    "       'lat_to_min_lat_air_lv2', 'lon_to_mean_lon_air_lv2',\n",
    "       'lon_to_max_lon_air_lv2', 'lon_to_min_lon_air_lv2',\n",
    "       'lat_to_mean_lat_hpg_lv1', 'lat_to_max_lat_hpg_lv1',\n",
    "       'lat_to_min_lat_hpg_lv1', 'lon_to_mean_lon_hpg_lv1',\n",
    "       'lon_to_max_lon_hpg_lv1', 'lon_to_min_lon_hpg_lv1',\n",
    "       'lat_to_mean_lat_hpg_lv2', 'lat_to_max_lat_hpg_lv2',\n",
    "       'lat_to_min_lat_hpg_lv2', 'lon_to_mean_lon_hpg_lv2',\n",
    "       'lon_to_max_lon_hpg_lv2', 'lon_to_min_lon_hpg_lv2']\n",
    "\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### categorical to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_data['air_area_genre'] = full_data['air_area_name'] + '-' + full_data['air_genre_name'] \n",
    "full_data['air_store_dow'] = full_data['air_store_id'] + '-' + full_data['dow'].astype(str)\n",
    "full_data['air_store_dow_holiday'] = full_data['air_store_id'] + '-' + full_data['dow'].astype(str) + '-' + full_data['holiday_flg'].astype(str)\n",
    "\n",
    "cat_cat_vars = ['air_area_genre','air_store_dow', 'air_store_dow_holiday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding air_area_genre\n",
      "Label Encoding air_store_dow\n",
      "Label Encoding air_store_dow_holiday\n",
      "Label-encoded feaures: ['air_area_genre_le', 'air_store_dow_le', 'air_store_dow_holiday_le']\n"
     ]
    }
   ],
   "source": [
    "LBL = preprocessing.LabelEncoder()\n",
    "\n",
    "cat_cat_LE_vars=[]\n",
    "cat_cat_LE_map=dict()\n",
    "for cat_var in cat_cat_vars:\n",
    "    print (\"Label Encoding %s\" % (cat_var))\n",
    "    LE_var=cat_var+'_le'\n",
    "    full_data[LE_var]=LBL.fit_transform(full_data[cat_var].astype(str))\n",
    "    cat_cat_LE_vars.append(LE_var)\n",
    "    cat_cat_LE_map[cat_var]=LBL.classes_\n",
    "    \n",
    "print (\"Label-encoded feaures: %s\" % (cat_cat_LE_vars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target aggregation\n",
    "\n",
    "This sometimes works for timeseries problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = full_data[:train_size].groupby(['air_store_id','dow','holiday_flg'])['visitors'].\\\n",
    "            agg([np.mean, np.max, np.min, np.median]).\\\n",
    "            reset_index().\\\n",
    "            rename(columns={'mean':'mean_visitors',\n",
    "                           'amax':'max_visitors',\n",
    "                           'amin':'min_visitors',\n",
    "                           'median':'median_visitors'})\n",
    "            \n",
    "full_data = pd.merge(full_data, tmp, how='left', on=['air_store_id','dow','holiday_flg'])\n",
    "\n",
    "tmp = full_data[:train_size].groupby(['air_store_id','dow', 'holiday_flg']).\\\n",
    "            apply(lambda x:( (x.weight * x.visitors).sum() / x.weight.sum() )).\\\n",
    "            reset_index().rename(columns={0:'wmean_visitors'})\n",
    "        \n",
    "full_data = pd.merge(full_data, tmp, how='left', on=['air_store_id','dow','holiday_flg'])    \n",
    "target_aggr_vars = ['mean_visitors', 'max_visitors', 'min_visitors', 'median_visitors', 'wmean_visitors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "\n",
    "We all run XGBoost models using a couple of combinations of features as well as with different missing value settings just to see how differently they perform.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numerical features + label-encoded categorical features\n",
    "Let's get started with the simplest combination: **numerical features + label-encoded categorical features** without additional transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: (252108, 118) test data size: (32019, 118)\n"
     ]
    }
   ],
   "source": [
    "full_vars = num_vars + LE_vars + num_num_vars + cat_cat_LE_vars + target_aggr_vars\n",
    "    \n",
    "train = full_data[:train_size]\n",
    "y = full_data[:train_size][target_var][:train_size].values\n",
    "test = full_data[train_size:]\n",
    "ids = full_data[train_size:][train_size:].id.values\n",
    "\n",
    "print ('train data size:', train.shape, 'test data size:', test.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = train[(train['visit_date']<=datetime.datetime.strptime('2017-03-09', '%Y-%m-%d').date()) \n",
    "      & (train['visit_date']>datetime.datetime.strptime('2016-04-01', '%Y-%m-%d').date())][full_vars].values\n",
    "train_y = np.log1p(train[(train['visit_date']<=datetime.datetime.strptime('2017-03-09', '%Y-%m-%d').date()) \n",
    "      & (train['visit_date']>datetime.datetime.strptime('2016-04-01', '%Y-%m-%d').date())]['visitors'].values)\n",
    "\n",
    "val_x = train[(train['visit_date']>datetime.datetime.strptime('2017-03-09', '%Y-%m-%d').date())][full_vars].values\n",
    "val_y = np.log1p(train[(train['visit_date']>datetime.datetime.strptime('2017-03-09', '%Y-%m-%d').date())]['visitors'].values)\n",
    "print (train_x.shape, val_x.shape, train_x.shape[0]+ val_x.shape[0])\n",
    "\n",
    "\n",
    "xgtrain = xgb.DMatrix(train_x, label=train_y)\n",
    "xgval=xgb.DMatrix(val_x,label=val_y)\n",
    "\n",
    "watchlist  = [ (xgtrain,'train'),(xgval,'eval')]\n",
    "\n",
    "\n",
    "best_xgb_params = {'colsample_bytree': 0.7,\n",
    " 'eta': 0.1,\n",
    " 'gamma': 1,\n",
    " 'max_depth': 10,\n",
    " 'min_child_weight': 3,\n",
    " 'nthread': 8,\n",
    " 'objective': 'reg:linear',\n",
    " 'seed': 1234,\n",
    " 'subsample': 1}\n",
    "\n",
    "print (best_xgb_params)\n",
    "\n",
    "model = xgb.train(best_xgb_params, \n",
    "                  xgtrain, \n",
    "                  num_boost_round=100000,\n",
    "                  evals=watchlist,\n",
    "                  early_stopping_rounds=50,\n",
    "                  verbose_eval=50)    \n",
    "best_iteration = model.best_iteration\n",
    "best_score = model.best_score\n",
    "print ('best_score: %f, best_iteration: %d' % (best_score, best_iteration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.feature_names = full_vars\n",
    "feature_importance = pd.DataFrame.from_dict(model.get_fscore(), orient='index')\n",
    "feature_importance.columns = ['importance']\n",
    "feature_importance.importance = feature_importance.importance/ feature_importance.importance.sum()\n",
    "feature_importance.sort_values(by='importance').head(30).plot(kind='barh',figsize=(4,20))\n",
    "feature_importance.sort_values(by='importance',ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = train[full_vars].values\n",
    "train_y = np.log1p(train['visitors'].values)\n",
    "model = xgb.train(best_xgb_params, \n",
    "                  xgb.DMatrix(train_x, label=train_y), \n",
    "                  num_boost_round=best_iteration)    \n",
    "test['visitors'] = model.predict(xgb.DMatrix(test[full_vars].values))\n",
    "test['visitors'] = np.expm1(test['visitors']).clip(lower=0.)\n",
    "sub = test[['id','visitors']].copy()\n",
    "sub[['id', 'visitors']].to_csv('../output/sub_starter.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "Feature engineering is the key, if not the most important, to the success of a data science projecct including Kaggle competition. It requires a data scientist to have excellent knowledge of Machine Learning algorithms, good sense of business, programming skills and, last but not least, hacker spirits.\n",
    "\n",
    "In this week's lecture we've learnt how to:\n",
    "\n",
    "* Preprocess data for\n",
    "    * Numeric features\n",
    "    * Categorical features\n",
    "* Impute missing values\n",
    "* Select features\n",
    "\n",
    "# Recommended Kaggle posts:\n",
    "\n",
    "* [A Very Extensive Recruit Exploratory Analysis](https://www.kaggle.com/captcalculator/a-very-extensive-recruit-exploratory-analysis)\n",
    "* [https://www.kaggle.com/headsortails/be-my-guest-recruit-restaurant-eda](https://www.kaggle.com/headsortails/be-my-guest-recruit-restaurant-eda)\n",
    "* [Surprise Me](https://www.kaggle.com/the1owl/surprise-me)\n",
    "* [Things that make this competition interesting (and fun)](https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting/discussion/45120)\n",
    "\n",
    "\n",
    "# Additional readings\n",
    "* [Applied Predictive Modeling - Chapter 3 Data Pre-Processing](http://appliedpredictivemodeling.com/toc/)\n",
    "* [机器学习特征工程实用技巧大全](https://zhuanlan.zhihu.com/p/26444240)\n",
    "* [Discover Feature Engineering](http://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/)\n",
    "* [Selecting good features – Part IV: stability selection, RFE and everything side by side](http://blog.datadive.net/selecting-good-features-part-iv-stability-selection-rfe-and-everything-side-by-side/)\n",
    "\n",
    "\n",
    "# Assignments\n",
    "1. Run this notebook and make submissions\n",
    "2. Experiment whatever feature engineering you could think of and see how they perform"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
